{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOOz2vcpK9n6lCRXrmtzFfX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuqiShi/test/blob/master/Cuda_tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDhgH659fMP7",
        "outputId": "7af0426f-5dc9-47ac-9df9-99fc96764985"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.7 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.7 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2023.1-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.6.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.3)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp310-cp310-linux_x86_64.whl size=661975 sha256=e3aacbd0c708605e756f4be02145c9226566f8918ce35928e0e9b4552e5f3a90\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/7b/06/82a395a243fce00035dea9914d92bbef0013401497d849f8bc\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.4 pycuda-2022.2.2 pytools-2023.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as drv\n",
        "\n",
        "drv.init()\n",
        "\n",
        "print(\"%d device(s) found!\" %drv.Device.count())\n",
        "\n",
        "for ordinal in range(drv.Device.count()):\n",
        "  dev = drv.Device(ordinal)\n",
        "  print(\"Device #%d: %s\" % (ordinal, dev.name()))\n",
        "  print(\"   Compute Capability: %d.%d\" % dev.compute_capability())\n",
        "  print(\"   Totel Memory: %s GB\" % (dev.total_memory()//(1024*1024*1024)))\n",
        "  atts = [(str(att),value)\n",
        "          for att, value in list(dev.get_attributes().items())]\n",
        "  atts.sort()\n",
        "\n",
        "  for att, value in atts:\n",
        "    print(f\"        {att}:{value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep5sjvw2lDH-",
        "outputId": "c62d097c-0889-49fc-f6a2-c49a1bbdfc81"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 device(s) found!\n",
            "Device #0: Tesla T4\n",
            "   Compute Capability: 7.5\n",
            "   Totel Memory: 14 GB\n",
            "        ASYNC_ENGINE_COUNT:3\n",
            "        CAN_MAP_HOST_MEMORY:1\n",
            "        CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM:1\n",
            "        CLOCK_RATE:1590000\n",
            "        COMPUTE_CAPABILITY_MAJOR:7\n",
            "        COMPUTE_CAPABILITY_MINOR:5\n",
            "        COMPUTE_MODE:DEFAULT\n",
            "        COMPUTE_PREEMPTION_SUPPORTED:1\n",
            "        CONCURRENT_KERNELS:1\n",
            "        CONCURRENT_MANAGED_ACCESS:1\n",
            "        DIRECT_MANAGED_MEM_ACCESS_FROM_HOST:0\n",
            "        ECC_ENABLED:1\n",
            "        GENERIC_COMPRESSION_SUPPORTED:0\n",
            "        GLOBAL_L1_CACHE_SUPPORTED:1\n",
            "        GLOBAL_MEMORY_BUS_WIDTH:256\n",
            "        GPU_OVERLAP:1\n",
            "        HANDLE_TYPE_POSIX_FILE_DESCRIPTOR_SUPPORTED:1\n",
            "        HANDLE_TYPE_WIN32_HANDLE_SUPPORTED:0\n",
            "        HANDLE_TYPE_WIN32_KMT_HANDLE_SUPPORTED:0\n",
            "        HOST_NATIVE_ATOMIC_SUPPORTED:0\n",
            "        INTEGRATED:0\n",
            "        KERNEL_EXEC_TIMEOUT:0\n",
            "        L2_CACHE_SIZE:4194304\n",
            "        LOCAL_L1_CACHE_SUPPORTED:1\n",
            "        MANAGED_MEMORY:1\n",
            "        MAXIMUM_SURFACE1D_LAYERED_LAYERS:2048\n",
            "        MAXIMUM_SURFACE1D_LAYERED_WIDTH:32768\n",
            "        MAXIMUM_SURFACE1D_WIDTH:32768\n",
            "        MAXIMUM_SURFACE2D_HEIGHT:65536\n",
            "        MAXIMUM_SURFACE2D_LAYERED_HEIGHT:32768\n",
            "        MAXIMUM_SURFACE2D_LAYERED_LAYERS:2048\n",
            "        MAXIMUM_SURFACE2D_LAYERED_WIDTH:32768\n",
            "        MAXIMUM_SURFACE2D_WIDTH:131072\n",
            "        MAXIMUM_SURFACE3D_DEPTH:16384\n",
            "        MAXIMUM_SURFACE3D_HEIGHT:16384\n",
            "        MAXIMUM_SURFACE3D_WIDTH:16384\n",
            "        MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS:2046\n",
            "        MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH:32768\n",
            "        MAXIMUM_SURFACECUBEMAP_WIDTH:32768\n",
            "        MAXIMUM_TEXTURE1D_LAYERED_LAYERS:2048\n",
            "        MAXIMUM_TEXTURE1D_LAYERED_WIDTH:32768\n",
            "        MAXIMUM_TEXTURE1D_LINEAR_WIDTH:268435456\n",
            "        MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH:32768\n",
            "        MAXIMUM_TEXTURE1D_WIDTH:131072\n",
            "        MAXIMUM_TEXTURE2D_ARRAY_HEIGHT:32768\n",
            "        MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES:2048\n",
            "        MAXIMUM_TEXTURE2D_ARRAY_WIDTH:32768\n",
            "        MAXIMUM_TEXTURE2D_GATHER_HEIGHT:32768\n",
            "        MAXIMUM_TEXTURE2D_GATHER_WIDTH:32768\n",
            "        MAXIMUM_TEXTURE2D_HEIGHT:65536\n",
            "        MAXIMUM_TEXTURE2D_LINEAR_HEIGHT:65000\n",
            "        MAXIMUM_TEXTURE2D_LINEAR_PITCH:2097120\n",
            "        MAXIMUM_TEXTURE2D_LINEAR_WIDTH:131072\n",
            "        MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT:32768\n",
            "        MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH:32768\n",
            "        MAXIMUM_TEXTURE2D_WIDTH:131072\n",
            "        MAXIMUM_TEXTURE3D_DEPTH:16384\n",
            "        MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE:32768\n",
            "        MAXIMUM_TEXTURE3D_HEIGHT:16384\n",
            "        MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE:8192\n",
            "        MAXIMUM_TEXTURE3D_WIDTH:16384\n",
            "        MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE:8192\n",
            "        MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS:2046\n",
            "        MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH:32768\n",
            "        MAXIMUM_TEXTURECUBEMAP_WIDTH:32768\n",
            "        MAX_BLOCKS_PER_MULTIPROCESSOR:16\n",
            "        MAX_BLOCK_DIM_X:1024\n",
            "        MAX_BLOCK_DIM_Y:1024\n",
            "        MAX_BLOCK_DIM_Z:64\n",
            "        MAX_GRID_DIM_X:2147483647\n",
            "        MAX_GRID_DIM_Y:65535\n",
            "        MAX_GRID_DIM_Z:65535\n",
            "        MAX_PERSISTING_L2_CACHE_SIZE:0\n",
            "        MAX_PITCH:2147483647\n",
            "        MAX_REGISTERS_PER_BLOCK:65536\n",
            "        MAX_REGISTERS_PER_MULTIPROCESSOR:65536\n",
            "        MAX_SHARED_MEMORY_PER_BLOCK:49152\n",
            "        MAX_SHARED_MEMORY_PER_BLOCK_OPTIN:65536\n",
            "        MAX_SHARED_MEMORY_PER_MULTIPROCESSOR:65536\n",
            "        MAX_THREADS_PER_BLOCK:1024\n",
            "        MAX_THREADS_PER_MULTIPROCESSOR:1024\n",
            "        MEMORY_CLOCK_RATE:5001000\n",
            "        MEMORY_POOLS_SUPPORTED:1\n",
            "        MULTIPROCESSOR_COUNT:40\n",
            "        MULTI_GPU_BOARD:0\n",
            "        MULTI_GPU_BOARD_GROUP_ID:0\n",
            "        PAGEABLE_MEMORY_ACCESS:0\n",
            "        PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES:0\n",
            "        PCI_BUS_ID:0\n",
            "        PCI_DEVICE_ID:4\n",
            "        PCI_DOMAIN_ID:0\n",
            "        READ_ONLY_HOST_REGISTER_SUPPORTED:1\n",
            "        RESERVED_SHARED_MEMORY_PER_BLOCK:0\n",
            "        SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO:32\n",
            "        STREAM_PRIORITIES_SUPPORTED:1\n",
            "        SURFACE_ALIGNMENT:512\n",
            "        TCC_DRIVER:0\n",
            "        TEXTURE_ALIGNMENT:512\n",
            "        TEXTURE_PITCH_ALIGNMENT:32\n",
            "        TOTAL_CONSTANT_MEMORY:65536\n",
            "        UNIFIED_ADDRESSING:1\n",
            "        WARP_SIZE:32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "    #include <stdio.h>\n",
        "\n",
        "    __global__ void say_hi()\n",
        "    {\n",
        "        printf(\"I am %dth thread in threadIdx.x:%d.threadIdx.y:%d blockIdx.:%d blockIdx.y:%d blockDim.x:%d blockDim.y:%d gridDim.x:%d gridDim.y:%d\\\\n\",threadIdx.x,threadIdx.y,blockIdx.x,blockIdx.y,blockDim.x,blockDim.y,gridDim.x,gridDim.y);\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "func = mod.get_function(\"say_hi\")\n",
        "func(block=(4, 4, 1), grid=(2, 2, 1))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s85HgAoAVlH1",
        "outputId": "390a9d04-bd4d-4a78-9843-16e907249a0b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as drv\n",
        "import pycuda.tools\n",
        "import pycuda.autoinit\n",
        "import numpy\n",
        "import numpy.linalg as la\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "__global__ void multiply_them(float *dest, float *a, float *b)\n",
        "{\n",
        "    const int i = threadIdx.x;\n",
        "    dest[i] = a[i] * b[i];\n",
        "}\n",
        "\"\"\")\n",
        "multiply_them = mod.get_function(\"multiply_them\")\n",
        "\n",
        "a = numpy.random.randn(400).astype(numpy.float32)\n",
        "b = numpy.random.randn(400).astype(numpy.float32)\n",
        "\n",
        "dest = numpy.zeros_like(a)\n",
        "multiply_them(\n",
        "        drv.Out(dest), drv.In(a), drv.In(b),\n",
        "        block=(400,1,1), grid=(1,1))\n",
        "\n",
        "print(dest-a*b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmSaDNbnrzm9",
        "outputId": "6d83ef26-c09d-4ee8-ac95-2ce4d955389c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.autoinit\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.driver as cuda\n",
        "import numpy\n",
        "\n",
        "free_bytes, total_bytes = cuda.mem_get_info()\n",
        "exp = 10\n",
        "while True:\n",
        "    fill_floats = free_bytes / 4 -(1<<exp)\n",
        "    if fill_floats < 0:\n",
        "        raise RuntimeError(\"couldn't find allocatable size\")\n",
        "    try:\n",
        "        print(\"alloc\", fill_floats)\n",
        "        ary = gpuarray.zeros((fill_floats,), dtype=numpy.float32)\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    exp += 1\n",
        "\n",
        "ary.fill(float(\"nan\"))\n",
        "\n",
        "print(\"fill %d out of %d bytes with NaNs\" % (fill_floats*4, free_bytes))"
      ],
      "metadata": {
        "id": "a4ZFpUoUuknz",
        "outputId": "dd93df88-4113-43e9-8f1a-f3a1c2af274d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alloc 3928701952.0\n",
            "alloc 3928700928.0\n",
            "alloc 3928698880.0\n",
            "alloc 3928694784.0\n",
            "alloc 3928686592.0\n",
            "alloc 3928670208.0\n",
            "alloc 3928637440.0\n",
            "alloc 3928571904.0\n",
            "alloc 3928440832.0\n",
            "alloc 3928178688.0\n",
            "alloc 3927654400.0\n",
            "alloc 3926605824.0\n",
            "alloc 3924508672.0\n",
            "alloc 3920314368.0\n",
            "alloc 3911925760.0\n",
            "alloc 3895148544.0\n",
            "alloc 3861594112.0\n",
            "alloc 3794485248.0\n",
            "alloc 3660267520.0\n",
            "alloc 3391832064.0\n",
            "alloc 2854961152.0\n",
            "alloc 1781219328.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-92575f1cf797>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfill_floats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfree_bytes\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m<<\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfill_floats\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"couldn't find allocatable size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"alloc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_floats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: couldn't find allocatable size"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.autoinit\n",
        "import numpy\n",
        "from pycuda.curandom import rand as curand\n",
        "\n",
        "a_gpu = curand((50,))\n",
        "b_gpu = curand((50,))\n",
        "\n",
        "from pycuda.elementwise import ElementwiseKernel\n",
        "lin_comb = ElementwiseKernel(\n",
        "        \"float a, float *x, float b, float *y, float *z\",\n",
        "        \"z[i] = my_f(a*x[i], b*y[i])\",\n",
        "        \"linear_combination\",\n",
        "        preamble=\"\"\"\n",
        "        __device__ float my_f(float x, float y)\n",
        "        {\n",
        "            return sin(x*y);\n",
        "        }\n",
        "        \"\"\")\n",
        "\n",
        "c_gpu = gpuarray.empty_like(a_gpu)\n",
        "lin_comb(5, a_gpu, 6, b_gpu, c_gpu)\n",
        "print(c_gpu)\n",
        "import numpy.linalg as la\n",
        "print(la.norm(c_gpu.get() - numpy.sin((5*a_gpu*6*b_gpu).get())) < 1e-5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlXTVE5y5Ml8",
        "outputId": "4ce0ba76-174a-4ed8-d357-95fadd38ea12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.7231871   0.8806899   0.35798535 -0.99658346 -0.32457775  0.6996876\n",
            " -0.27785546  0.8788663  -0.5593305   0.06763591  0.03788458 -0.99138665\n",
            " -0.34647107  0.27459607  0.20271116 -0.12944542  0.99667215  0.7766698\n",
            " -0.00384076  0.6894252   0.00813597 -0.24195908  0.8352214  -0.9998702\n",
            "  0.98412627 -0.6304864  -0.3948932   0.99810153  0.24599268 -0.860303\n",
            "  0.9541138   0.41623122  0.89988786  0.33793125  0.53693366 -0.8019235\n",
            "  0.18725929  0.12536752 -0.44190723 -0.9646584   0.4871217  -0.75611264\n",
            " -0.9975576   0.28726465  0.07722988 -0.95213723  0.20477505  0.90327436\n",
            " -0.91743916  0.12283815]\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit , pycuda.compiler\n",
        "import numpy as np\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "\n",
        "a = np.random.randn(4,4).astype(np.float32)\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "    __global__ void doublify(float *a)\n",
        "    {\n",
        "    int idx = threadIdx.x + threadIdx.y*4;\n",
        "    a[idx] *= 2;\n",
        "    }\n",
        "    \"\"\")\n",
        "func = mod.get_function(\"doublify\")\n",
        "func(a_gpu, block=(4,4,1), grid=(1,1), shared=0)\n",
        "a_doubled = np.empty_like(a)\n",
        "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
        "print(\"doubled a:\")\n",
        "print(a_doubled)\n",
        "print(\"original a:\")\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ1QWWJ9iyac",
        "outputId": "7922ed23-3ee5-47d5-97d9-5a908a6e9f93"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doubled a:\n",
            "[[-0.44884303  1.0370659  -0.02796388  2.768781  ]\n",
            " [-0.850241   -0.01396938 -0.6562841  -3.4277756 ]\n",
            " [-1.2917259   0.9839839  -0.17862996 -2.0675328 ]\n",
            " [-2.152982   -0.4433159   0.1991783  -0.66262203]]\n",
            "original a:\n",
            "[[-0.22442152  0.51853293 -0.01398194  1.3843905 ]\n",
            " [-0.4251205  -0.00698469 -0.32814205 -1.7138878 ]\n",
            " [-0.64586294  0.49199194 -0.08931498 -1.0337664 ]\n",
            " [-1.076491   -0.22165795  0.09958915 -0.33131102]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python\n",
        "# Conway's Game of Life Accelerated with PyCUDA\n",
        "# Luis Villasenor\n",
        "# lvillasen@gmail.com\n",
        "# 3/26/2016\n",
        "# Licence: GPLv3\n",
        "# Usage: python GameOfLife.py n n_iter\n",
        "# where n is the board size and n_iter the number of iterations\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.tools\n",
        "import pycuda.autoinit\n",
        "import pycuda.gpuarray as gpuarray\n",
        "from pycuda.compiler import SourceModule\n",
        "import sys\n",
        "import numpy as np\n",
        "from pylab import cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "n=int(sys.argv[1])\n",
        "n_iter=int(sys.argv[2])\n",
        "n_block=16\n",
        "n_grid=int(n/n_block);\n",
        "n=n_block*n_grid;\n",
        "def random_init(n):\n",
        "    #np.random.seed(100)\n",
        "    M=np.zeros((n,n)).astype(np.int32)\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            M[j,i]=np.int32(np.random.randint(2))\n",
        "    return M\n",
        "mod = SourceModule(\"\"\"\n",
        "__global__ void step(int *C, int *M)\n",
        "{\n",
        "  int count;\n",
        "  int n_x = blockDim.x*gridDim.x;\n",
        "  int i = threadIdx.x + blockDim.x*blockIdx.x;\n",
        "  int j = threadIdx.y + blockDim.y*blockIdx.y;\n",
        "  int threadId = j*n_x+i;\n",
        "  int i_left; int i_right; int j_down; int j_up;\n",
        "  if(i==0) {i_left=n_x-1;} else {i_left=i-1;}\n",
        "  if(i==n_x-1) {i_right=0;} else {i_right=i+1;}\n",
        "  if(j==0) {j_down=n_x-1;} else {j_down=j-1;}\n",
        "  if(j==n_x-1) {j_up=0;} else {j_up=j+1;}\n",
        "  count = C[j*n_x+i_left] + C[j_down*n_x+i]\n",
        "    + C[j*n_x+i_right] + C[j_up*n_x+i] + C[j_up*n_x+i_left]\n",
        "    + C[j_down*n_x+i_right] + C[j_down*n_x+i_left]\n",
        "    + C[j_up*n_x+i_right];\n",
        "\n",
        "// Modify matrix M according to the rules B3/S23:\n",
        "//A cell is \"Born\" if it has exactly 3 neighbours,\n",
        "//A cell \"Survives\" if it has 2 or 3 living neighbours; it dies otherwise.\n",
        "  if(count < 2 || count > 3) M[threadId] = 0; // cell dies\n",
        "  if(count == 2) M[threadId] = C[threadId];// cell stays the same\n",
        "  if(count == 3) M[threadId] = 1; // cell either stays alive, or is born\n",
        "}\n",
        "\"\"\")\n",
        "func = mod.get_function(\"step\")\n",
        "C=random_init(n)\n",
        "M = np.empty_like(C)\n",
        "C_gpu = gpuarray.to_gpu( C )\n",
        "M_gpu = gpuarray.to_gpu( M )\n",
        "for k in range(n_iter):\n",
        "  func(C_gpu,M_gpu,block=(n_block,n_block,1),grid=(n_grid,n_grid,1))\n",
        "  C_gpu, M_gpu = M_gpu, C_gpu\n",
        "print(\"%d live cells after %d iterations\" %(np.sum(C_gpu.get()),n_iter))\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "ax = fig.add_subplot(111)\n",
        "fig.suptitle(\"Conway's Game of Life Accelerated with PyCUDA\")\n",
        "ax.set_title('Number of Iterations = %d'%(n_iter))\n",
        "myobj =plt.imshow(C_gpu.get(),origin='lower',cmap='Greys',  interpolation='nearest',vmin=0, vmax=1)\n",
        "plt.pause(.01)\n",
        "plt.draw()\n",
        "m=n_iter\n",
        "while True:\n",
        "    m+=1\n",
        "    func(C_gpu,M_gpu,block=(n_block,n_block,1),grid=(n_grid,n_grid,1))\n",
        "    C_gpu, M_gpu = M_gpu, C_gpu\n",
        "    myobj.set_data(C_gpu.get())\n",
        "    ax.set_title('Number of Iterations = %d'%(m))\n",
        "    plt.pause(.01)\n",
        "    plt.draw()"
      ],
      "metadata": {
        "id": "jAHiaL-vu5QP",
        "outputId": "ad584d19-41cc-45f9-b7df-cc561c0594f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-dced09422d9a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mn_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '-f'"
          ]
        }
      ]
    }
  ]
}